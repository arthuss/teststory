{
  "url": "https://en.wikipedia.org/wiki/Global_catastrophic_risk",
  "title": "Global catastrophic risk",
  "text": "A global catastrophic risk or a doomsday scenario is a hypothetical event that could damage human well-being on a global scale, endangering or even destroying modern civilization. Existential risk is a related term limited to events that could cause full-blown human extinction or permanently and drastically curtail humanity's existence or potential.\nIn the 21st century, a number of academic and non-profit organizations have been established to research global catastrophic and existential risks, formulate potential mitigation measures, and either advocate for or implement these measures.\n\n\n== Definition and classification ==\n\n\n=== Defining global catastrophic risks ===\nThe term global catastrophic risk \"lacks a sharp definition\", and generally refers (loosely) to a risk that could inflict \"serious damage to human well-being on a global scale\".\nHumanity has suffered large catastrophes before. Some of these have caused serious damage but were only local in scope—e.g. the Black Death may have resulted in the deaths of a third of Europe's population, 10% of the global population at the time. Some were global, but were not as severe—e.g. the 1918 influenza pandemic killed an estimated 3–6% of the world's population. Most global catastrophic risks would not be so intense as to kill the majority of life on earth, but even if one did, the ecosystem and humanity would eventually recover (in contrast to existential risks).\nSimilarly, in Catastrophe: Risk and Response, Richard Posner singles out and groups together events that bring about \"utter overthrow or ruin\" on a global, rather than a \"local or regional\" scale. Posner highlights such events as worthy of special attention on cost–benefit grounds because they could directly or indirectly jeopardize the survival of the human race as a whole.\n\n\n=== Defining existential risks ===\nExistential risks are defined as \"risks that threaten the destruction of humanity's long-term potential.\" The instantiation of an existential risk (an existential catastrophe) would either cause outright human extinction or irreversibly lock in a drastically inferior state of affairs. Existential risks are a sub-class of global catastrophic risks, where the damage is not only global but also terminal and permanent, preventing recovery and thereby affecting both current and all future generations.\n\n\n==== Non-extinction risks ====\nWhile extinction is the most obvious way in which humanity's long-term potential could be destroyed, there are others, including unrecoverable collapse and unrecoverable dystopia. A disaster severe enough to cause the permanent, irreversible collapse of human civilisation would constitute an existential catastrophe, even if it fell short of extinction. Similarly, if humanity fell under a totalitarian regime, and there were no chance of recovery, then such a dystopia would also be an existential catastrophe. Bryan Caplan writes that \"perhaps an eternity of totalitarianism would be worse than extinction\". (George Orwell's novel Nineteen Eighty-Four suggests an example.) A dystopian scenario shares the key features of extinction and unrecoverable collapse of civilization: before the catastrophe humanity faced a vast range of bright futures to choose from; after the catastrophe, humanity is locked forever in a terrible state.\n\n\n== Potential sources of risk ==\n\nPotential global catastrophic risks are conventionally classified as anthropogenic or non-anthropogenic hazards. Examples of non-anthropogenic risks are an asteroid or comet impact event, a supervolcanic eruption, a natural pandemic, a lethal gamma-ray burst, a geomagnetic storm from a coronal mass ejection destroying electronic equipment, natural long-term climate change, hostile extraterrestrial life, or the Sun transforming into a red giant star and engulfing the Earth billions of years in the future.\n\nAnthropogenic risks are those caused by humans and include those related to technology, governance, and climate change. Technologica",
  "fetched_at": "2026-02-09T02:44:57.788599"
}